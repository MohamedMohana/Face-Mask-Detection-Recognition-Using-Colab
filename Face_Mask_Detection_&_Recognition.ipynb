{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Mask Detection & Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "y_Rbx2AxJQIo",
        "1r6_qNf6JhEh",
        "0NUtdFh4UW2T",
        "EGBHVTM6NIKF"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedMohana/Face-Mask-Detection-Recognition-Using-Colab/blob/main/Face_Mask_Detection_%26_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Rbx2AxJQIo"
      },
      "source": [
        "#Load Google Drive with Colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GMwuCsQJIIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518ac342-e74c-489c-ef57-336ba4dbb66e"
      },
      "source": [
        "# To read data directories and paths from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8eusOGPMWoH"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/\"Your Files\"/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmBbdZ-hMe30"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujgyjTJuNAtv"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r6_qNf6JhEh"
      },
      "source": [
        "# Import Important Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw9HF2tcKXun",
        "outputId": "b4b47e8f-1c05-441b-fc15-fe6abcccbb3d"
      },
      "source": [
        "#Install the face_recognition Lib \n",
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8v_OGDf6JKop"
      },
      "source": [
        "#To Preprocess the data (work only with \"\"GPU\"\")\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "#Convert images to vector (number) (work only with \"\"GPU\"\")\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "#To load the saved model\n",
        "from tensorflow.keras.models import load_model\n",
        "#Get the date \n",
        "from datetime import datetime\n",
        "#Get the off-time\n",
        "from time import sleep\n",
        "#Import the library \n",
        "import face_recognition\n",
        "#Import numpy for array\n",
        "import numpy as np\n",
        "#Import Time\n",
        "import time\n",
        "#Import OpenCV lib for Pictures \n",
        "import cv2\n",
        "#Import files from the OS\n",
        "import os\n",
        "#Import Javacode\n",
        "from IPython.display import display, Javascript\n",
        "#Allow Java code to work in the Browser\n",
        "from google.colab.output import eval_js\n",
        "#To convert bytes that have binary or text data into ASCII characters\n",
        "from base64 import b64decode, b64encode\n",
        "#Image processing functions\n",
        "import imutils\n",
        "#To use cv2.imshow in google colab\n",
        "from google.colab.patches import cv2_imshow\n",
        "#To load the image\n",
        "from PIL import Image\n",
        "#To dealing with various types of I/O\n",
        "import io \n",
        "#Access system-specific parameters and functions\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NUtdFh4UW2T"
      },
      "source": [
        "#Train the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTLD3fQCUecA"
      },
      "source": [
        "##Import libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haLQ1nP0UiiA"
      },
      "source": [
        "# import the necessary DL packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP7x6A70Unhn"
      },
      "source": [
        "## Initialize the initial learning rate, number of epochs to train for,and batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqXEOHx2UrVu"
      },
      "source": [
        "INIT_LR = 1e-4\n",
        "EPOCHS = 20\n",
        "BS = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjK2FQLJUtRf"
      },
      "source": [
        "## Load dataset & Categorize it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgT-SRQRUybH",
        "outputId": "1dae6a7d-78dc-4063-def8-0d804e09a37c"
      },
      "source": [
        "DIRECTORY = r\"Mask_Data\"\n",
        "\n",
        "CATEGORIES = [\"with_mask\", \"without_mask\"]\n",
        "# grab the list of images in our dataset directory, then initialize\n",
        "# the list of data (i.e., images) and class images\n",
        "print(\"[INFO] loading images...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsz-p-UHiBJm"
      },
      "source": [
        "## Create two list:\n",
        "- Data & Labels\n",
        "- Join each image to its right label based on the dataset\n",
        "- Resize all images to 24 x 24\n",
        "- Convert the Images to array --> _faster the process of the traning_\n",
        "- Pre-process the input to suit the model --> in our case here MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKqGo4J7h9Sq"
      },
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DIRECTORY, category)\n",
        "    for img in os.listdir(path):\n",
        "    \timg_path = os.path.join(path, img)\n",
        "    \timage = load_img(img_path, target_size=(224, 224))\n",
        "    \timage = img_to_array(image)\n",
        "    \timage = preprocess_input(image)\n",
        "    \tdata.append(image)\n",
        "    \tlabels.append(category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLiVFwmNkFXu"
      },
      "source": [
        "## Perform label binarizer encoding on the labels\n",
        "* with mask [0  1] \n",
        "* without mask [1  0]\n",
        "\n",
        "_This will help the output when caculating the probability using the activation function_ \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLhE0cTTkH9c"
      },
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvlZmbLdsWNT"
      },
      "source": [
        "## Chage data types to arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FchcFu6IsKDM"
      },
      "source": [
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB7r8PIWsrzO"
      },
      "source": [
        "##Split the data to train/test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gs4VFzxsH0s"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJc6xbxj0dR9"
      },
      "source": [
        "## Construct the training image generator for data augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzltPccr0eLZ"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNRqwWrx24AN"
      },
      "source": [
        "##MobileNetV2\n",
        "\n",
        "- Since we are trasfer learning the model, so we acually do not need the top or last layer which beem trained to detect all the objects. so we will freez it and put our worn layers at the end to solve our problem and detect only the object we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGft19aR2yLp",
        "outputId": "1dfa2893-9fa7-4c04-c0b3-da1d8dfcc96b"
      },
      "source": [
        "# load the MobileNetV2 network, ensuring the head FC layer sets are left off\n",
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "# place the head FC model on top of the base model (this will become\n",
        "# the actual model we will train)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i8eWaiN4atD"
      },
      "source": [
        "## Loop over all layers in the base model and freeze them so they will *not* be updated during the first training process\n",
        "\n",
        "- This is because these layes been already trianed before, so why westing time doing again for months ^_^"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AzUo33E43Jz"
      },
      "source": [
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNnk_KXe41Rt"
      },
      "source": [
        "## Compile our model\n",
        "- We use the loss finction __binary crossentropy__ and __accuracy__ as a metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeS_J8hz7cjY",
        "outputId": "104fa258-6d3c-4e33-9dda-a95192a50231"
      },
      "source": [
        "# compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDZNQRs4_KKd"
      },
      "source": [
        "##Start training \n",
        "\n",
        "- Only the head layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r55n5NSU_N48",
        "outputId": "5c2a2195-8c1c-40e0-e942-488707d07664"
      },
      "source": [
        "# train the head of the network\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 52s 360ms/step - loss: 0.4196 - accuracy: 0.8316 - val_loss: 0.1705 - val_accuracy: 0.9752\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 33s 352ms/step - loss: 0.1520 - accuracy: 0.9641 - val_loss: 0.0978 - val_accuracy: 0.9765\n",
            "Epoch 3/20\n",
            "95/95 [==============================] - 33s 350ms/step - loss: 0.0961 - accuracy: 0.9792 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
            "Epoch 4/20\n",
            "95/95 [==============================] - 33s 349ms/step - loss: 0.0777 - accuracy: 0.9782 - val_loss: 0.0644 - val_accuracy: 0.9817\n",
            "Epoch 5/20\n",
            "95/95 [==============================] - 33s 348ms/step - loss: 0.0628 - accuracy: 0.9822 - val_loss: 0.0563 - val_accuracy: 0.9831\n",
            "Epoch 6/20\n",
            "95/95 [==============================] - 33s 350ms/step - loss: 0.0563 - accuracy: 0.9855 - val_loss: 0.0489 - val_accuracy: 0.9857\n",
            "Epoch 7/20\n",
            "95/95 [==============================] - 33s 348ms/step - loss: 0.0486 - accuracy: 0.9878 - val_loss: 0.0478 - val_accuracy: 0.9844\n",
            "Epoch 8/20\n",
            "95/95 [==============================] - 33s 347ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0443 - val_accuracy: 0.9883\n",
            "Epoch 9/20\n",
            "95/95 [==============================] - 33s 344ms/step - loss: 0.0424 - accuracy: 0.9878 - val_loss: 0.0472 - val_accuracy: 0.9831\n",
            "Epoch 10/20\n",
            "95/95 [==============================] - 33s 345ms/step - loss: 0.0379 - accuracy: 0.9904 - val_loss: 0.0420 - val_accuracy: 0.9870\n",
            "Epoch 11/20\n",
            "95/95 [==============================] - 33s 345ms/step - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.0392 - val_accuracy: 0.9909\n",
            "Epoch 12/20\n",
            "95/95 [==============================] - 33s 344ms/step - loss: 0.0358 - accuracy: 0.9895 - val_loss: 0.0374 - val_accuracy: 0.9922\n",
            "Epoch 13/20\n",
            "95/95 [==============================] - 33s 344ms/step - loss: 0.0369 - accuracy: 0.9901 - val_loss: 0.0360 - val_accuracy: 0.9922\n",
            "Epoch 14/20\n",
            "95/95 [==============================] - 33s 343ms/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0337 - val_accuracy: 0.9948\n",
            "Epoch 15/20\n",
            "95/95 [==============================] - 33s 342ms/step - loss: 0.0337 - accuracy: 0.9898 - val_loss: 0.0459 - val_accuracy: 0.9804\n",
            "Epoch 16/20\n",
            "95/95 [==============================] - 32s 340ms/step - loss: 0.0312 - accuracy: 0.9904 - val_loss: 0.0385 - val_accuracy: 0.9844\n",
            "Epoch 17/20\n",
            "95/95 [==============================] - 32s 341ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 0.0310 - val_accuracy: 0.9948\n",
            "Epoch 18/20\n",
            "95/95 [==============================] - 32s 339ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0329 - val_accuracy: 0.9883\n",
            "Epoch 19/20\n",
            "95/95 [==============================] - 32s 340ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.0309 - val_accuracy: 0.9922\n",
            "Epoch 20/20\n",
            "95/95 [==============================] - 33s 343ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 0.0346 - val_accuracy: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsO7kHjlD-ZX"
      },
      "source": [
        "##Validation \n",
        "* Make predictions on the testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psQGYk6XD98c",
        "outputId": "e27beecf-05dd-4b4c-a241-ef28d034831b"
      },
      "source": [
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Mh0cnAEPSx"
      },
      "source": [
        "## Largest predicted probability\n",
        "* So we can know it belongs to which label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TATxM21hEPjL"
      },
      "source": [
        "predIdxs = np.argmax(predIdxs, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HY675dMEhG0"
      },
      "source": [
        "##Classification report for all:\n",
        "- Accuracy \n",
        "- Precision\n",
        "- Recall \n",
        "- F1-score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iamtE8wEhhD",
        "outputId": "8bba2c17-6d84-46c9-f27e-b6801957999f"
      },
      "source": [
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_mask       0.98      0.99      0.99       383\n",
            "without_mask       0.99      0.98      0.99       384\n",
            "\n",
            "    accuracy                           0.99       767\n",
            "   macro avg       0.99      0.99      0.99       767\n",
            "weighted avg       0.99      0.99      0.99       767\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuhB_j9AGAA-"
      },
      "source": [
        "## Save the model so we can use it again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBxBzBTCH34K"
      },
      "source": [
        "# serialize the model to disk\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(\"mask_detector.model\", save_format=\"h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoKUP8bWIAUP"
      },
      "source": [
        "##Plot the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-_FVggoEoC2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "cf577bfd-f0c5-4bf7-93f7-d84f1ca80ab7"
      },
      "source": [
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "#plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "#plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "#print(H.history.keys())\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "#plt.savefig(\"plot.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxU9f4/8Nc5s7MzgCACpoQa4hJiuOWSZItmZi7VVTPUFvpdb90y06tX+7pmmZbpjYw0zYrKpduiKe5bpbK4lCkuXAwQYdhhYGbO5/fHDEcGBhiWWYT38/HAmbPNeZ/jzHmf8/mc8/lwjDEGQgghBADv6AAIIYQ4D0oKhBBCRJQUCCGEiCgpEEIIEVFSIIQQIqKkQAghRERJgVjt0KFD4DgON27caNJyHMfh888/t1FU7dfw4cMxc+ZMR4dB2hhKCm0Qx3EN/t11113N+txBgwYhOzsbgYGBTVouOzsbEyZMaNY6m4oSkGUvvfQSJBIJ1q9f7+hQiJOjpNAGZWdni3/bt28HACQnJ4vjTp06ZTZ/VVWVVZ8rl8sREBAAnm/a1yYgIABKpbJJy5DWU1ZWhm3btmH+/PnYuHGjo8MBYP13jtgfJYU2KCAgQPxTq9UAAD8/P3Fchw4d8MEHH+CZZ56Bp6cnpk6dCgD417/+hXvuuQcuLi4IDg7Giy++iKKiIvFzaxcfVQ/v27cPQ4cOhYuLC8LDw7F7926zeGqfvXMchw0bNmDq1Klwd3dHUFAQVqxYYbZMfn4+Jk6cCFdXV/j7+2PhwoV49tlnERMT06J989lnnyE8PBxyuRxBQUFYsGAB9Hq9OP3YsWMYPHgw3N3d4e7ujj59+uDnn38Wpy9fvhxdu3aFQqGAn58fHnroIVRUVNS7vi+++ALR0dHw9PSEr68vRo8ejUuXLonTr1+/Do7j8PXXX2PMmDFwcXFB165dsXnzZrPPycjIwMMPPwyVSoXg4GCsW7fO6m3+8ssvERYWhgULFiAjIwO//vprnXkSExPRr18/KJVK+Pj44JFHHkFBQYE4ff369QgPD4dCoUCHDh3w5JNPitPuuusuLF261OzzZs6cieHDh4vDw4cPx4wZM7Bw4UJ07NgRISEhVu0fAMjNzcVzzz0Hf39/KJVKdO/eHZ9++ikYY+jatSuWL19uNn9ZWRk8PDywdetWq/cRuY2SQjv11ltvYdCgQUhOThZ/0CqVCh9//DF+//13bN68GYcOHcLs2bMb/azXX38d8+fPR1paGqKjozF58mSzA0p96x86dChSU1Mxb948zJ8/H/v37xenP/fcc0hLS8MPP/yAAwcO4MaNG9i1a1eLtvnHH39EbGwspk6divPnz2P16tVYv3493nrrLQCAXq/H2LFjER0djeTkZCQnJ2Px4sVwcXEBAOzYsQMrV67E+++/j8uXL2Pfvn145JFHGlxnZWUlFixYgOTkZOzbtw8SiQSjR4+uc6b85ptvYtq0aTh79iyeeuopzJw5Uzw4MsbwxBNPID8/H4cOHcL333+P//73v0hOTrZqu+Pj4zF9+nQoFAo89dRTiI+PN5u+adMmTJkyBePGjUNycjIOHjyIhx9+GAaDAQCwaNEizJ07F3FxcTh37hz27NmDyMhIq9Zd09dff41bt25h//792Ldvn1X7p6KiAsOGDUNaWhq2bduG33//HevWrYOLiws4jsOsWbOQkJCAmq31fPXVV5BKpZg4cWKTYyQAGGnTDh48yACwzMxMcRwAFhsb2+iyO3bsYHK5nBkMBoufVT28fft2cZmcnBwGgO3Zs8dsfVu3bjUb/vvf/262rh49erA333yTMcbYpUuXGACWlJQkTq+qqmJBQUFs5MiRDcZce101DRkyhE2cONFs3Nq1a5lSqWSVlZVMo9EwAOzgwYMWl3/vvfdYWFgYq6qqajCGhuTn5zMA7NixY4wxxq5du8YAsNWrV4vz6PV65ubmxj766CPGGGP79u1jANiff/4pzpObm8uUSiWbMWNGg+tLSUlhcrmc5eXlMcYYO3nyJHNxcWGFhYXiPMHBwezll1+2uHxpaSlTKpXsnXfeqXcdnTt3ZkuWLDEbN2PGDDZs2DBxeNiwYSwsLEz8LtWn9v755JNPmEKhMPv+1pSTk8NkMhnbt2+fOG7AgAFs9uzZDa6H1I+uFNqp++67r864HTt2YOjQoQgMDISbmxv+9re/oaqqCjk5OQ1+Vt++fcX3/v7+kEgkuHnzptXLAEBgYKC4zO+//w4AGDBggDhdJpMhKiqq4Y1qxIULFzB06FCzccOGDYNWq8WVK1fg7e2NmTNn4qGHHsIjjzyClStX4s8//xTnnTRpEnQ6HTp37ozp06dj69atKCkpaXCdqampeOKJJ9ClSxe4u7uLxSYZGRlm89XcHxKJBB06dDDbH76+vujWrZs4j5+fH7p3797oNsfHx2PMmDHw8fEBYNynQUFBYnFebm4uMjMzMWrUKIvLX7hwAVqttt7pTdGvX7869VGN7Z8zZ84gPDwcQUFBFj/T398fjz/+uFhXcv78efzyyy+YNWtWi+NtrygptFOurq5mw7/++ismTpyIoUOHYufOnUhOTsZHH30EoPFKQblcXmecIAhNWobjuDrLcBzX4GfYwsaNG3HmzBk8+OCDOHz4MCIiIsTilk6dOuHixYv49NNP0aFDByxZsgTdu3dHZmamxc8qLy/HqFGjwHEcNm3ahN9++w2nTp0Cx3F19qk1+6OpqiuYd+3aBalUKv5dvny5VSuceZ43K74BAJ1OV2e+2t+5puyfhrz44ovYtWsX8vLy8Mknn2DgwIGIiIho3sYQSgrE6NixY/D19cXSpUsRHR2Nbt26Nfl5hNYSHh4OADh58qQ4Tq/X48yZMy363J49e+LIkSNm4w4fPgyVSoXQ0FBxXEREBP75z39i9+7dmDFjBj7++GNxmkKhwMMPP4xVq1bh3LlzKC8vr7eu448//sCtW7ewbNkyDB8+HPfccw8KCgrqHEAbEx4ejry8PFy+fFkcl5eXZ3YVY8mXX34JqVSK1NRUs79Dhw7h7Nmz+PXXX9GhQwcEBQVh79699a5bqVTWOx0AOnTogKysLLNxKSkpjW6XNfunX79++P333xv8Lj7wwAMICQlBfHw8tm7dSlcJLSR1dADEOXTv3h23bt1CQkICRowYgWPHjmHDhg0OiSUsLAyPPfYYXn75ZcTHx8PPzw+rV69GcXGxVVcP//vf/5Cammo2LjAwEPPmzcNjjz2GlStXYvz48UhNTcXixYvx2muvQS6XIz09HRs3bsRjjz2G4OBgZGVl4ejRo2KlakJCAgRBwH333QcvLy/s378fJSUlYhKrrXPnzlAoFFi3bh1ee+01XL9+HW+++WaTr4BGjhyJPn36YMqUKVi3bh3kcjnmzp0LmUzW4HLx8fF44okn0KtXrzrTBgwYgPj4eERHR2PRokV46aWX4O/vjwkTJkAQBBw8eBBPPfUUfH198dprr2Hx4sVQqVR48MEHUVFRgZ9++gnz5s0DAMTExGDDhg144okn0LlzZ3z00UfIyMgQ73yrjzX75+mnn8aqVaswduxYrFq1CqGhobh69Sry8vIwefJkAMarqueffx4LFiyASqUSx5NmcnCdBrGx+iqaLVXGLliwgHXo0IG5uLiwRx55hH3xxRcMALt27ZrFz7L02YwxJpFI2KZNm+pdn6X1jxw5kj377LPicF5eHnvyySeZSqVifn5+bOHChWzChAlszJgxDW4vAIt/K1asYIwxtnnzZtajRw8mk8lYYGAgmz9/PtPpdIwxxrKystgTTzzBOnXqxORyOevYsSObOXOmWCm7fft2NnDgQObl5cVUKhXr2bMn++STTxqM55tvvmF33303UygUrG/fvuzQoUNm+6e6ovno0aNmy4WGhrJFixaJw9euXWMPPvggUygUrFOnTmzt2rVs2LBh9VY0p6Sk1Knwr2nt2rVmFc6ff/456927N5PL5UytVrNHH32UFRQUMMYYEwSBrV27lnXr1o3JZDLWoUMHNmHCBPGziouL2ZQpU5iXlxfz8/NjixYtsljRbCnWxvYPY4xlZ2ezqVOnMh8fH6ZQKFj37t3NpjPG2K1bt5hMJmNxcXEWt5dYj2OMel4jzs9gMKBHjx4YO3YsVq9e7ehwiJO5cOECIiIikJqaij59+jg6nDsaFR8Rp3TkyBHk5ubi3nvvRUlJCdasWYPr169j+vTpjg6NOJHKykrk5eVh3rx5GDFiBCWEVkBJgTglg8GApUuXIj09HTKZDBERETh48KDF8nHSfn355ZeIjY1Fz5498e233zo6nDaBio8IIYSI6JZUQgghIkoKhBBCRHd8nULth2as5evri7y8vFaOpvVQfC1D8bWcs8dI8TVfQ32i0JUCIYQQESUFQgghIkoKhBBCRHapU9iwYQOSk5Ph6elp8WlUxhg2bdqElJQUKBQKxMXFoWvXrvYIjRBCSA12uVIYPnw45s+fX+/0lJQU5OTk4IMPPsDzzz+PTz75xB5hEUIIqcUuSSE8PBxubm71Tj99+jSGDh0KjuPQrVs3lJWVNdqdIyGEkNbnFHUKGo0Gvr6+4rCPjw80Go0DIyKEkPbpjntOISkpCUlJSQCAlStXmiWTppBKpc1e1h4ovpZpzfgExlClF1BlEFCpN/5VGQQwBuMfGBgAMFM73cxYTya2221qSYax28M5OaUAk0PCc5DwHKSmVwl3+704rvo9Z3xvqT8GxhgEVuMVxleh9nh2e7yU5yGVGD9bxtf9bFv8HzPGYGCAQWCm2BgYQ43YbsfHasQvDuP2+JICLXRMKQ5bnN/0aqg1LICJ+1NqYR/X2fe1/o8kPAe9cPt7UWWo+V5AlV5AelkhKqogDlcZBOgMDJV6ATqDsVc9nufAcwAH4yvPceD528McV2M8x4HjII6P6OiOzt4urfr/AzhJUlCr1WYPeeTn59fbQUdMTAxiYmLE4eY+HOLMD5YAzhcfYwxVpi+0Vs/g4uGJ3DwNdAITv+w6AzMNV783/lj0BtM4gUFn+gEZGCDjOcglpj8pDznPQS7lIJfwt8eL783HSSWc+Fk6A0NlrfdKFzfkFxabfoCm2A2W3guoNC1nPOibtkFv+qGb4nYm1QcJoPpAb0w2rUHKw5iYJBxkEgl4MEh5DlIedQ6egukALzAGvcBgEGq8Z4AgMOiZ+Xgn25V3tBf7++ORbt7NWrahh9ecIilERUVhz549GDx4MC5fvgwXFxd4ezdvY9u76oN3hV5AhU6A1vRaoRPEcRV6AVrTNK14oK8+C2am9wxagyC+rzIILfpB85zxoCKXGM9KefFMy5g89C3rjtgqUp6DwpRYZKYko5BykPE85FIObnKpON5SIqr5KpMYz9o4GM/qIL43/sPDON00ePs9x4ED4OHhgcKiIhgEQM8YBNOBVG86gzYINd6bhg1CjfeMGc8cTZ9tdlZpWrc4vsZZqBgzB3EdBtPBu/rArheM76VyBUrLK4zTBQZ9rfl5joeUAyS88Sy2OqHwfK33NeaR8IDUdNbLc6h1Vlw3Vl6Mt8Z4U/yeHh4oKy0xzofb89fcTvFzYDwrr16WAyfuW8H0f2AwJS29UP8+rzksfp9N32mZ6ftRPezn443ykmJxmqz6u8fzkJoK7quvLGtf3VVfhQqoddUjzs/grpDY5Hdil1ZS165di99//x0lJSXw9PTEpEmToNfrAQCjRo0CYwwJCQlIS0uDXC5HXFycWZ+5DbkTmrkQGENOiQ5XC7S4otHiqkaLnFKd6Ut8+8suqTGskMtg0OvB8+bjq18B3D7g13q19uAt5QGFlIdSwkMh5aGQclBKje+VUk4cr5Rypumm8VIevl6e0JaXQm4qfhB/DKYfhFz8oRjHS0wHrfoYxCsM45l7zfeWzuh1Bib+CBWm9SokxoO7jOcQ4OeDsuJCyGpM55vYDaYtOduVoCXOHiPF13wOv1J45ZVXGpzOcRxmzpxpj1BsziAw3CiuEg/+Vwu0uKqpRIXpVFjKAyGeCoT5KMFxnHh2UrMs1MAAqZSH1mC8BNcxQGDC7XlMZ9VKGQcXGQ8fFylUMh4qKQ+VTGJ6NR7AVTLzcbenGQ/WzWX8wrfeQVbCc1Dxxnhbg6+XCnn6slb5LELaE6coPrpTVRkEZBRW4lpBJa5ojFcBGYWVqDIYT9XlEg5dvBUY3sUDoWoluqqVCPGUQyZp/MDnzGcZhJC2i5JCM/yZV4GPfstBRmElTMd/uMh4dFUr8XCYl5gAOrkb7y4hhJA7BSWFJtIZGD44mY0KnYAnwn3QVa1AV28l/N1kTlVmTQghzUFJoYl+vKTBjeIqLBwehKhO9T+lTQghdyKneKL5TqGp0OOrs/mICnSlhEAIaZMoKTTBlpRc6ASGmVH+jg6FEEJsgpKClf64VY6D14ox7h41OrrLHR0OIYTYBCUFKxgEho2nb8JHJcWEnj6ODocQQmyGkoIVkq4U4YqmEtMjO7Taw1WEEOKM6AjXiNJKA7am3ULPDirc39nd0eEQQohNUVJoxBdnb6GsyoBZUf4Ntt1DCCFtASWFBlwv0GL35UI8HOaFLt5KR4dDCCE2R0mhHowxfHz6JlzlEjzT28/R4RBCiF1QUqjH0YwSXMitwNQ+fjZrt5wQQpwNJQULKnQCNifnIlStQEyop6PDIYQQu6GkYMG3F/KRX6HHrCh/auWUENKuUFKoJbukCrv+0GB4Fw/c49f6nWITQogzo6RQS8KZm5DxHJ69t4OjQyGEELujpFDD6b9KceqvMkzu5QO1iloVJ4S0P5QUTHQGAZ+cuYlOHnKM6a52dDiEEOIQlBRMvrtYgOwSHWb269CiDu0JIeRORkkBQH65Dt+cz0N0kBsiA6nzHEJI+0VJAcDm5FswCEBsJFUuE0Lat3afFC7cLMeRjGI8Ea5GAHWeQwhp59p1UjAIxvaN/Fyo8xxCCAHaeVL4Ob0Q1wsr8Vy/DlBI2/WuIIQQAO04KRRW6LAt7RZ6+btgUDB1nkMIIUA7Tgofn8hAuU7A89R5DiGEiNplUrii0eK/53Mwups3QrwUjg6HEEKcRrtMCr/nlkPtKsdTvX0dHQohhDiVdtnAz2M91Jh0X1dUFBc6OhRCCHEq7fJKAQBc5e0yHxJCSIPsdmRMTU3Fpk2bIAgCRo4ciXHjxplNz8vLw/r161FWVgZBEPDMM88gMjLSXuERQgiBnZKCIAhISEjAggUL4OPjg3nz5iEqKgpBQUHiPNu3b8fAgQMxatQo3LhxAytWrKCkQAghdmaX4qP09HQEBATA398fUqkUgwYNwqlTp8zm4TgO5eXlAIDy8nJ4e3vbIzRCCCE12OVKQaPRwMfndjMSPj4+uHz5stk8EydOxNKlS7Fnzx5UVlZi4cKF9giNEEJIDU5T23r8+HEMHz4cjz32GC5duoR169Zh9erV4Hnzi5mkpCQkJSUBAFauXAlf3+bdViqVSpu9rD1QfC1D8bWcs8dI8dmGXZKCWq1Gfn6+OJyfnw+12rx3swMHDmD+/PkAgG7dukGn06GkpASenp5m88XExCAmJkYczsvLa1ZMvr6+zV7WHii+lqH4Ws7ZY6T4mi8wMLDeaXapUwgNDUV2djZyc3Oh1+tx4sQJREVFmc3j6+uL8+fPAwBu3LgBnU4HDw8Pe4RHCCHExC5XChKJBLGxsVi2bBkEQcCIESMQHByMxMREhIaGIioqCtOmTUN8fDx+/PFHAEBcXBy1SUQIIXZmtzqFyMjIOreYTp48WXwfFBSEJUuW2CscQgghFrTbJ5oJIYTURUmBEEKIiJICIYQQESUFQgghIkoKhBBCRJQUCCGEiCgpEEIIEVFSIIQQIqKkQAghRERJgRBCiIiSAiGEEBElBUIIISJKCoQQQkSUFAghhIgoKRBCCBFZnRQ2b96M69ev2zAUQgghjmZ1JzuCIGDZsmXw8PDA/fffj/vvvx8+Pj62jI0QQoidWZ0UYmNjMX36dKSkpODo0aPYsWMHwsLCMHToUERHR0OpVNoyTkIIIXbQpO44eZ5Hv3790K9fP2RmZuKDDz7Ahg0b8Mknn2Dw4MGYNGkS1Gq1rWIlhBBiY01KCuXl5fjll19w9OhRZGRkIDo6GjNmzICvry9++OEHLF++HO+++66tYiWEEGJjVieF1atXIy0tDffccw8efPBB9O/fHzKZTJw+bdo0TJ8+3RYxEkIIsROrk0JYWBhmzJgBLy8vi9N5nsfGjRtbLTBCCCH2Z/Utqb1794Zerzcbl5eXZ3abqkKhaLXACCGE2J/VSWHdunUwGAxm4/R6PT788MNWD4oQQohjWJ0U8vLy4O/vbzYuICAAt27davWgCCGEOIbVSUGtVuPq1atm465evQpvb+9WD4oQQohjWF3RPHr0aLzzzjsYO3Ys/P39cfPmTXz//fcYP368LeMjhBBiR1YnhZiYGLi6uuLAgQPIz8+Hj48Ppk2bhgEDBtgyPkIIIXbUpIfXBg4ciIEDB9oqFkIIIQ7WpKRQWFiI9PR0lJSUgDEmjn/ggQdaPTBCCCH2Z3VS+O2337Bu3Tp07NgRmZmZCA4ORmZmJnr06EFJgRBC2girk0JiYiLi4uIwcOBAPPfcc1i1ahUOHjyIzMxMW8ZHCCHEjpr0nELt+oRhw4bhyJEjrR4UIYQQx7D6SsHDwwOFhYXw8vKCn58fLl26BHd3dwiCYNXyqamp2LRpEwRBwMiRIzFu3Lg685w4cQLffPMNOI5D586d8Y9//MP6LSGEENJiVieFkSNH4uLFixgwYABGjx6Nt956CxzHYcyYMY0uKwgCEhISsGDBAvj4+GDevHmIiopCUFCQOE92djZ27dqFJUuWwM3NDUVFRc3bIkIIIc1mdVIYO3YseN5Y2jRs2DD07NkTWq3W7MBen/T0dAQEBIjNZAwaNAinTp0yW3b//v146KGH4ObmBgDw9PRs0oYQQghpOauSgiAImDp1KjZv3iz2oeDr62v1SjQajVl/zj4+Prh8+bLZPFlZWQCAhQsXQhAETJw4EX379q3zWUlJSUhKSgIArFy5sklx1CSVSpu9rD1QfC1D8bWcs8dI8dmGVUmB53kEBgaipKTEZt1tCoKA7OxsLFq0CBqNBosWLcK7774LV1dXs/liYmIQExMjDufl5TVrfb6+vs1e1h4ovpah+FrO2WOk+JovMDCw3mlWFx8NGTIEb7/9Nh555BH4+PiA4zhxWkRERIPLqtVq5Ofni8P5+fl1kotarUZYWBikUik6dOiAjh07Ijs7G3fffbe1IRJCCGkhq5PC3r17AQDffPON2XiO4xrtUyE0NBTZ2dnIzc2FWq3GiRMnMHv2bLN57rvvPhw7dgwjRoxAcXExsrOz6zTVTQghxLasTgrr169v9kokEgliY2OxbNkyCIKAESNGIDg4GImJiQgNDUVUVBT69OmDtLQ0vPrqq+B5HlOmTIG7u3uz10kIIaTpOFazEaM7UHUFdVM5c3kfQPG1FMXXcs4eI8XXfK1Sp/DSSy/VO+0///lP0yIihBDilKxOCn//+9/NhgsKCvDTTz9h8ODBrR4UIYQQx7A6KYSHh9cZ17NnTyxbtgyPPvpoqwZFCCHEMaxuEM8SqVSK3Nzc1oqFEEKIgzWp6eyaKisrkZKSgnvvvbfVgyKEEOIYVieFmg+fAYBCocCYMWMwdOjQVg+KEEKIY1idFOLi4mwZByGEECdgdZ3Crl27kJ6ebjYuPT0d3333XasHRQghxDGsTgo//fRTnWayg4KC8NNPP7V6UIQQQhzD6qSg1+shlZqXNkmlUlRVVbV6UIQQQhzD6qTQtWtX/Pzzz2bj9u7di65du7Z6UIQQQhzD6ormZ599FkuXLsWRI0fg7++PmzdvorCwEAsXLrRlfIQQQuzI6qQQHByM999/H2fOnEF+fj6io6PRr18/KJVKW8ZHCCHEjqxOChqNBnK53Kyto9LSUmg0Gpv1xkYIIcS+rK5TeOedd6DRaMzGaTQavPvuu60eFCGEEMewOilkZWUhJCTEbFxISAj++uuvVg+KEEKIY1idFDw8PJCTk2M2Licnh3pHI4SQNsTqOoURI0Zg9erVeOqpp+Dv74+cnBwkJibigQcesGV8hBBC7MjqpDBu3DhIpVJs3boV+fn58PHxwQMPPIDHHnvMlvERQgixI6uTAs/zGDt2LMaOHSuOEwQBKSkpiIyMtElwhBBC7MvqpFBTRkYGDh8+jGPHjsFgMCAhIaG14yKEEOIAVieFoqIiHD16FEeOHEFGRgY4jsNzzz2HESNG2DI+QgghdtRoUjh58iQOHz6MtLQ0dOrUCUOGDMGcOXPwr3/9CwMGDIBcLrdHnIQQQuyg0aSwdu1auLm54dVXX8V9991nj5gIIYQ4SKNJ4aWXXsLhw4fx3nvvITQ0FEOGDMGgQYPAcZw94iOEEGJHjSaF4cOHY/jw4bh16xYOHz6MPXv2YMuWLQCAlJQUDB06FDxv9TNwhBBCnJjVFc1+fn6YMGECJkyYgIsXL+Lw4cP47LPP8OWXXyI+Pt6WMRJCCLGTRpPC2bNnER4ebtbrWo8ePdCjRw/Exsbi1KlTNg2QEEKI/TSaFL7//nu8//776N69OyIjIxEZGSk2lS2TyTBo0CCbB0kIIcQ+Gk0K//rXv1BZWYlz584hJSUFO3bsgKurK+69915ERkaiW7dud2SdgqEg39EhEEKI07GqTkGhUCAqKgpRUVEAgP/9739ISUnBV199hb/++gs9e/bE6NGjERYWZtNgW4vw49fI+yER/JrPwSlVjg6HEEKcRrOauQgJCUFISAgef/xxlJeXIy0tDRUVFa0dm81wXbuD6XXAxTSg7wBHh0MIIU7D6nKf8+fPIzc3FwBQUFCADz/8EBs2bEBVVRUGDhyI3r17N7h8amoq/vGPf+Dvf/87du3aVe98v/zyCyZNmoQrV65YG1rThYWDU7mAnTtju3UQQsgdyOqkkJCQINYdbNmyBQaDARzHWXU7qiAISEhIwPz587FmzRocP34cN27cqDNfRUUFdu/ebfNiKE4qg7zPfWDnzoAxZtN1EULIncTqpKDRaODr6wuDwYC0tDS88MILmDVrFiAJQAEAACAASURBVC5dutTosunp6QgICIC/vz+kUikGDRpk8VbWxMREPP7445DJZE3bimZQ9BsEFOQBN67bfF2EEHKnsLpOQaVSobCwEJmZmQgKCoJSqYRer4der290WY1GAx8fH3HYx8cHly9fNpvn6tWryMvLQ2RkJP773//W+1lJSUlISkoCAKxcuRK+vr7WboIZ7r4hKF4PuFz9A6739m/WZ9iSVCpt9rbZA8XXMs4eH+D8MVJ8tmF1Unj44Ycxb9486PV6TJ8+HQBw8eJFdOrUqcVBCIKALVu2IC4urtF5Y2JiEBMTIw7n5eU1a52+vr5ASChKfzmMimGPNuszbMnX17fZ22YPFF/LOHt8gPPHSPE1X2BgYL3TmtQd53333Qee5xEQEAAAUKvVePHFFxtdVq1WIz//9nMB+fn54gNwAKDVapGZmYm33noLAFBYWIhVq1bhjTfeQGhoqLUhNhnXOwrsx2/ASovBuXnYbD2EEHKnaNItqTWzy/nz58HzPMLDwxtdLjQ0FNnZ2cjNzYVarcaJEycwe/ZscbqLi4tZ722LFy/G1KlTbZoQAICL6Af2QyLYhRRw0cNsui5CCLkTWJ0UFi1ahKeffho9evTArl278OOPP4LneTz00EMYP358g8tKJBLExsZi2bJlEAQBI0aMQHBwMBITExEaGio+FGd3XcIANw/g3GmAkgIhhFifFDIzM9GtWzcAwP79+7Fo0SIolUosXLiw0aQAQGw3qabJkydbnHfx4sXWhtUiHC8xXi2cPw0mGMDxEruslxBCnJXVt6RW38+fk5MDAAgKCoKvry/KyspsE5m99OoHlJYA1y43Pi8hhLRxVl8pdO/eHZ9++ikKCgrQv7/xFs6cnBy4u7vbLDh74HpGgvE82NnT4EJ7ODocQghxKKuvFF5++WW4uLigc+fOmDRpEgAgKysLjz7qfLdzNgXn6gaE9gA7R/1CEEKI1VcK7u7ueOaZZ8zG1a4juFNxvfqD7fgMrCAfnLdP4wsQQkgbZXVS0Ov12LFjB44cOYKCggJ4e3tj6NChGD9+vFmvbHcirlc/Y1I4fwbc/aMcHQ4hhDiM1Ufzzz//HFeuXMGsWbPg5+eHW7duYfv27SgvLxefcL5jdeoMqH3Bzp4GKCkQQtoxq+sUfvnlF7zxxhvo06cPAgMD0adPH7z++us4efKkLeOzC47jwPWKAv5IA9PpHB0OIYQ4TJNvSW2ruF5RQGUFcPmCo0MhhBCHsbr4aODAgXj77bcxYcIEsaGn7du3Y+DAgbaMz3569AakMrBzp8GF93V0NIQQ4hBWJ4UpU6Zg+/btSEhIQEFBAdRqNQYNGmRV09l3Ak6hBHr0MtYrTJ7p6HAIIcQhrE4KUqkUkydPNmuaoqqqClOnTsWUKVNsEpy9cRFRYF99DHYzC5x//U3LEkJIW2V1nYIlHMe1VhxOgettbJiPnTvt4EgIIcQxWpQU2hrOLwAICKKkQAhptxotPjp//ny909pKfUJNXK9+YAd/BNNWgFOqHB0OIYTYVaNJ4T//+U+D0+/EPkgbwvWKAtv3HXAxDeg7wNHhEEKIXTWaFNavX2+POJxHWDigVBlbTaWkQAhpZ6hOoRZOKgPC+4KdO9PmH9gjhJDaKClYwPWKAgrzgRvXHR0KIYTYFSUFC7iIfgAAdpb6WCCEtC+UFCzgvNRASCjY+TOODoUQQuyKkkI9uN5RwJU/wUqLHR0KIYTYDSWFenC9ogAmgF1IcXQohBBiN5QU6nNXGODuCdDTzYSQdoSSQj04ngfXMxLsQjKYYHB0OIQQYheUFBrSOwooLQGuXnJ0JIQQYheUFBrAhd8L8DzYOboLiRDSPlBSaADn6gaE9gA7R88rEELaB0oKjeB69Qcyr4EV5Ds6FEIIsTlKCo2gjncIIe0JJYXGBIYAal+qVyCEtAuUFBrBcZzxQbY/UsF0OkeHQwghNkVJwQpcr/5ApRa4XH8vdIQQ0hY02slOa0lNTcWmTZsgCAJGjhyJcePGmU3/4YcfsH//fkgkEnh4eOCll16Cn5+fvcJrWI9egFQGdu6M8TZVQghpo+xypSAIAhISEjB//nysWbMGx48fx40bN8zmueuuu7By5Uq8++67GDBgAD7//HN7hGYVTqEEevQCO0uVzYSQts0uSSE9PR0BAQHw9/eHVCrFoEGDcOqU+b3/ERERUCgUAICwsDBoNBp7hGY1rlcUkJsFdjPL0aEQQojN2KX4SKPRwMfHRxz28fHB5cuX653/wIED6Nu3r8VpSUlJSEpKAgCsXLkSvr6+zYpJKpU2aVn90AeR/+XHcL36B1x69m7WOpuiqfHZG8XXMs4eH+D8MVJ8tmG3OgVrHTlyBFevXsXixYstTo+JiUFMTIw4nJeX16z1+Pr6Nm1ZqQIICELJL4dRPnBks9bZFE2Oz84ovpZx9vgA54+R4mu+wMDAeqfZpfhIrVYjP//2E8H5+flQq9V15jt79ix27tyJN954AzKZzB6hNQnXOwq4dB5MW+HoUAghxCbskhRCQ0ORnZ2N3Nxc6PV6nDhxAlFRUWbzXLt2DRs3bsQbb7wBT09Pe4TVZFyvKECvBy6mOToUQgixCbsUH0kkEsTGxmLZsmUQBAEjRoxAcHAwEhMTERoaiqioKHz++efQarV47733ABgvvebOnWuP8Kx39z2AUgV29jS4vgMcHQ0hhLQ6jjHGHB1ES2Rlmd8NxBiDVquFIAjgOK7e5RQKBSorK5u8PuHP80BpMbjIgQ1+fks1N77WwhgDz/NQKpUWt9OZy0sBiq81OHuMFF/zNVSn4HQVzS2l1Wohk8kglTa8aVKpFBKJpMmfz8J6AHk3AZkUnFzR3DAb1dz4WpNer4dWq4VKpXJoHIQQ+2lzzVwIgtBoQmgRpYvxtbzMdutwElKpFIIgODoMQogdtbmkYMsiHQDgpFJArgQqym26Hmdh6/1JCHEubS4p2IWLC1CpBSsqwB1eJUMIIWYoKTSHhxfg4goU5AE3s8D0ekdHRAghrYKSQjNwvATwCwB8Ohib1M76H1h5KQCgqKgImzdvbvJnTp06FUVFRU1e7pVXXsEPP/zQ5OUIIcSSNnf3UU3CVxvBMq9ZnsZxzSr64YK7gH9qlrGs3d0TTKkCbt0EcrPB3D1RVFqBLVu2YPr06WbL6fX6BivAt27d2uRYCCGktbXppGAPnEwO1rETUKABiguxYvH/4fr163jwwQchk8mgUCjg6emJ9PR0HDt2DLGxscjKykJlZSVmzJiBKVOmAACio6Oxe/dulJWVYcqUKYiOjsapU6cQEBCATz/91KrbQo8ePYolS5bAYDCgT58+WLFiBRQKBZYvX469e/dCKpVi6NCh+Pe//43vv/8ea9asAc/z8PDwwI4dO2y9qwghd4A2nRT4p2bVO00qlULfSnUBHMcb+3FWuWDeSy/iz/Sr2Pvt1zhx/nc8++yzOHDgAEJCQgAAq1evhre3NyoqKjB69Gg8+uijddqBunbtGuLj47Fq1Sq88MIL+Omnn/Dkk082GINWq8Wrr74qPiU+e/ZsbNmyBU8++SR2796NI0eOgOM4sYhq7dq12LZtGzp27NisYitCSNtEdQqtiFO5AP6BAM8ZK6EL8tG3Tx8xIQDAp59+ipiYGDz22GPIysrCtWt1i7eCg4MREREBAOjduzcyMzMbXfeVK1cQEhKC0NBQAMDEiRPx66+/wsPDAwqFAq+99hp++ukn8YojKioKr776KrZt2waDwdAam08IaQMoKbQyTiIBpDJjJbSuCi4STqyEPnHiBI4ePYrvv/8eSUlJiIiIsNiURXVnQ4Cx3aiWHLSlUil+/PFHjB49GklJSfjb3/4GAHj77bfxxhtvICsrC4888ojTdWpECHGMNl185Aiurq4oLS0F5+5pTAwcJ1ZCFxcVwdPTEyqVCunp6UhOTm619YaGhiIzMxPXrl1Dly5dsH37dgwYMABlZWWoqKjAyJEj0b9/fwwcOBAAcP36dURGRiIyMhIHDx5EVlaWxebMCSHtCyWFVqZWq9G/f3888MADUCqVxp6XPLyB4gIM73E3tup0GDZsGEJDQxEZGdlq61UqlXjvvffwwgsviBXNU6dORWFhIWJjY1FZWQnGGBYtWgQAWLp0Ka5duwbGGIYMGYKePXu2WiyEkDtXm2sltby8HC4uLo0u15oVzdZgFeXGhvQEA+DlA3h4NdiEhL3jq099+9OZW4AEKL7W4OwxUnzN165aSXVWnMoFLDAEyM81VkJXlIG5uAEKFSCXUxtDhBCnQEnBjjiJBMwvACgtBooKAM0t4wSeB1OoAIUSUKoAC01yz58/H6dOnTIbN3PmTEyePNkeoRNC2glKCnZW/SQ03D3B9DpAqwUqK4zNZRTmV88EvUIJJlcCSiWgUGH58uWODZwQ0i5QUnAgTioD3GSAmzsAgBkMxuRQWQFUVgIlhUCxscqHyeTGoiZTkoBUSkVOhJBWR0nBiXASibH1VRdXSKVS6KqqgKpKY5LQaoHyUqDU9PSxRAomVxiLmqr/KFEQQlqIkoIT43jeWMegVAGexn6Toau6XeRUVWXq7Md0AxkvMSUK+e1EIaNKbEKI9Sgp3EE4jrt9sIcnAIAJgjFRVFXe/ispAqrvNOZ4sJpJojpR8PQwOyGkLkoKrayoqAg7d+6s03R2Y6ZOnYoPP/wQnp6eTVqO43njXUsKpThOvKKomSjKSo3JAgA4DkwqAyRSQCIBeL7Ge4nZOEZ9NBPSrrTppPDJ6Zu4VqC1OI1rZn8KXbyVmBnlX+/04uJih/enYH5FYcQYA/T620lCVwUYDMb3BoPxoToL2NXLMPzwJeDmAbh7GpvvcPdEaUBHCFIFOC814OkNeKqND+RJJK22HYQQ+2vTScERli9fjoyMDLv1p7Bt2zZs27YNVVVV6NKlCz744AOoVCrcunULb775JjIyMgAAK1asQP/+/fHNrl2Ij48HANxzzz1Yt24dAFPSqE4ONV+1leDuHQhWWgSUFIH9lQGUFKGsrMS4XM1gqm+3NSWJmgmD8/QGvNTG5OHpZbzzihDidKiZi1aWmZkp9qFw4sQJTJs2zaw/hYKCArP+FL799luo1WqzpDB48GDs3bsXPXr0wAsvvIBRo0bV25+CRqMRG7J7++234efnh9jYWLz44ovo168fZs2aBYPBgLKyMmRnZ2PGjBn473//C7VaLcbSkPr2p4+XF/KuphsfwivSgBUVAIWa2++rh4sLAWahCMrFDZDVKMKSyoyvEikglZq/SqSm1mdrjJfKAKULoFIBKldA5QJO5SoOqzsFQVNRCSiUTll/4sxNIFRz9hgpvuajZi4cqG/fvnX6U9i9ezcAiP0p1G6dtLo/Bb1e32h/Cn/++SdWrVqF4uJilJWVYdiwYQCA48eP4/333wdgbH7bw8MD3377LcaMGSOur7GE0BBOKgWn9gXUvsbheuZjggEoKQaKNEBhdcLQAMVFgEFvLNIyvTKD3nh1otcZXyu14nRWPV/1MnodUFFhlnBqnt2IP0WOM969pXIRkwdUruCUqhrDpj+lCzgX03xKF7NpdGVD2gtKCjZW8yy7Zn8KKpUKEyZMsKo/Ba3Wcr0IALz66qtISEhAz549kZiYiJMnT7buBrQQx0tMRUjeQEhovcmjORhjxsRRUQ5UlJley8EqyuEm4VB6K9c4XlsBlJcZGyWsKAOKCsBybhjHV5QbE0z1Z9a3MpnclFxqJBKlyphclCrTg4W3/zil+bBxumkZmXmCEYvuxCSpA3SmV7154oRed3seQQAzCMaiPqHGq8FgTJaGWuMFA2AQao2r9b7GckVyGYSKCmNiN5imVc/PGCBXglPd3q7qfQKli3G8QiUmW3G6XNEmbpFmjLWJ7bCEkkIrq+5PwZKSkpJW70+htLQU/v7+0Ol02LlzJwICAgAAQ4YMwZYtW8yKjwYPHowZM2bg+eeft7r4yJlx1VcBShXg7XN7PAAXX1+UW3npznQ6QFudWCrEBMNMSab2NKY1zZNXbHxf/WdNcgEAiRS5SpXp6sd0kLcnnq/xJ7n9nuNv33nG8dDJZMbt4CzMz3HG5Cpuf7kxmZjUu/1cjWdv5ApjEaJMbvyTywGpHJxcbj6+5p9cbiw6lMmhVavBKrTG4eoixeo/mRSQmF7F8VLjSUp1jIwZ/3/LS41355Ub/1hZCVBWZhpfYuwkq7wMKCsxzVdm3F650tgagasb4OoOzs0DcHUXx1UEBIIxrsY4D+NVZwuKM1nN5M1LbHJjByWFVmaxPwWT4cOHY+vWra3an8KcOXMwZswY+Pj44N577xUT0v/93//hjTfewFdffQWe57FixQpERUVh9uzZmDBhAnieR0REBNauXdviGO50nEwGyIx3VZmNb+LnML3e9PR53T+zg2dlBZQ8B22VzlRPUn1Qq1WXIpMBEhk4S9OkproYTgJIah6wq28nltQ66N8++Ft7htuUMvHbD1aatrHi9vay6sSqrTCNN73XVYHpqowPYeqrgNIS0zid8bOq/6qqLNZLNatncZ431V9JjTFYqu+qJpUa675c3IwHfk81uMAQ40FeqTJepZaVgJWWGF/zbxkTR3kpwBiKLX0mxwOuroCLuzGxVl+liVdhta/ial3B1fyoKXHghj3cnL3QIKpodlLOEh/1p2Abzh4f4FwxMr3emDh0OmOS0FXCy90dhbdybxep6XWAXgdWXfSm05kXuZmmi3VWCpXxAO3qDq7mwb/6tZlFXUwQgIoyeMukKMjMuJ04ykuMia/6igOodRVW68qtnis4MblHRIILCW3W/qSKZkLIHU28Wrr9jCZkvr7gXOs+7Onokn6O5wFXd0h9fcHJVU4RU1NQUrhDUH8KhBB7sFtSSE1NxaZNmyAIAkaOHIlx48aZTdfpdPjwww9x9epVuLu745VXXkGHDh2avJ47vDSsXo7qT6Gt7k9CiGV2eapHEAQkJCRg/vz5WLNmDY4fP44bN26YzXPgwAG4urpi3bp1GD16NLZt29asdfE87xRl8W2BXq8H74QPfhFCbMcuVwrp6ekICAiAv7+xzaBBgwbh1KlTCAoKEuc5ffo0Jk6cCAAYMGAAPv3002bdC6xUKqHValFZWdngsgqFwuIzAs7C0fExxsDzPJRKZeMzE0LaDLskBY1GAx+f2/eR+/j44PLly/XOI5FI4OLigpKSEnh4eJjNl5SUhKSkJADAypUrzW75bApnubunPndCfM3d9/ZA8bWcs8dI8dnGHVfRHBMTg5iYGHG4ubfMOdPtdpZQfC1D8bWcs8dI8TVfQ7ek2qXAWK1WIz8/XxzOz8+v095PzXkMBgPKy8vh7u5uj/AIIYSY2CUphIaGIjs7G7m5udDr9Thx4gSioqLM5unXrx8OHToEAPjll1/Qs2fPNtu2CCGEOCu7PdGcnJyMzz77DIIgYMSIERg/fjwSExMRGhqKqKgoVFVV4cMPP8S1a9fg5uaGV155RayYJoQQYiesnZo7d66jQ2gQxdcyFF/LOXuMFJ9t0E3ohBBCRJQUCCGEiCSLFy9e7OggHKVr166ODqFBFF/LUHwt5+wxUnyt745vOpsQQkjroeIjQgghIkoKhBBCRHdcMxdNZa8mu5sjLy8P69evR2FhITiOQ0xMDB599FGzeS5cuIBVq1aJMUVHR2PChAl2iQ8AXn75ZSiVSvA8D4lEgpUrV5pNZ4xh06ZNSElJgUKhQFxcnN3KUbOysrBmzRpxODc3F5MmTcLo0aPFcY7Yfxs2bEBycjI8PT2xevVqAMa+tNesWYNbt27Bz88Pr776Ktzc3Oose+jQIezYsQMAMH78eAwfPtzmsW3duhVnzpyBVCqFv78/4uLi4OrqWmfZxr4Ltozx66+/xv79+8W20J5++mmL3dk29nu3VXxr1qwRe4Gs7q3wnXfeqbOsvfZhizj4llibMhgM7P/9v//HcnJymE6nY6+//jrLzMw0m2fPnj0sPj6eMcbYsWPH2HvvvWe3+DQaDbty5QpjjLHy8nI2e/bsOvGdP3+erVixwm4x1RYXF8eKiorqnX7mzBm2bNkyJggC+/PPP9m8efPsGN1tBoOBzZw5k+Xm5pqNd8T+u3DhArty5Qr75z//KY7bunUr27lzJ2OMsZ07d7KtW7fWWa6kpIS9/PLLrKSkxOy9rWNLTU1ler1ejNNSbIw1/l2wZYyJiYnsu+++a3A5a37vtoqvps8++4x98803FqfZax+2RJsuPqrZZLdUKhWb7K7p9OnT4tnYgAEDcP78ebt1LOPt7S2eVatUKnTq1AkajcYu624tp0+fxtChQ8FxHLp164aysjIUFBTYPY5z584hICAAfn5+dl93beHh4XWuAk6dOoVhw4YBAIYNG1bnewgYz3J79+4NNzc3uLm5oXfv3khNTbV5bH369IFEIgEAdOvWzeHfQUsxWsOa37ut42OM4eTJkxg8eHCrr9de2nTxUWs22W1rubm5uHbtGu6+++460y5duoQ5c+bA29sbU6dORXBwsF1jW7ZsGQDgwQcfNGuhFjDuv5rNA/v4+ECj0cDb29uuMR4/frzeH6Kj9x8AFBUVifvEy8sLRUVFdeap/X1Vq9V2P0AfOHAAgwYNqnd6Q98FW/v5559x5MgRdO3aFdOmTatzYLbm925rf/zxBzw9PdGxY8d653HkPrRGm04KdwqtVovVq1dj+vTpcHFxMZvWpUsXbNiwAUqlEsnJyXjnnXfwwQcf2C22JUuWQK1Wo6ioCEuXLkVgYCDCw8Pttn5r6PV6nDlzBs8880ydaY7ef5ZwHOeUjT3u2LEDEokE999/v8XpjvwujBo1SqwLSkxMxJYtWxAXF2eXdTdFQycnwJ3xe2rTxUd3QpPder0eq1evxv3334/o6Og6011cXMTezyIjI2EwGFBcXGy3+Kr3l6enJ/r374/09PQ602u2GW9pH9taSkoKunTpAi8vrzrTHL3/qnl6eorFagUFBRavRGt/XzUajd325aFDh3DmzBnMnj273oTV2HfBlry8vMDzPHiex8iRI3HlyhWL8TX2e7clg8GA3377rcErLUfuQ2u16aTg7E12M8bw0UcfoVOnThgzZozFeQoLC8U6jvT0dAiCYLekpdVqUVFRIb4/e/YsQkJCzOaJiorCkSNHwBjDpUuX4OLi4lRFR47cfzVFRUXh8OHDAIDDhw+jf//+debp27cv0tLSUFpaitLSUqSlpaFv3742jy01NRXfffcd5s6dC4VCYXEea74LtlSznuq3336zWARoze/dls6dO4fAwECzIqyaHL0PrdXmn2h25ia7L168iH//+98ICQkRE9HTTz8tnnmPGjUKe/bswd69eyGRSCCXyzFt2jR0797dLvHdvHkT7777LgDjWdCQIUMwfvx47N27V4yPMYaEhASkpaVBLpcjLi4OoaGhdokPMP644uLi8OGHH4pFbzXjc8T+W7t2LX7//XeUlJTA09MTkyZNQv/+/bFmzRrk5eWZ3ZJ65coV7Nu3Dy+++CIAY5n+zp07ARhvSR0xYoTNY9u5cyf0er1YRh8WFobnn38eGo0G8fHxmDdvXr3fBVuwFOOFCxdw/fp1cBwHPz8/PP/88/D29jaLEbD8e7dHfA888ADWr1+PsLAwjBo1SpzXUfuwJdp8UiCEEGK9Nl18RAghpGkoKRBCCBFRUiCEECKipEAIIURESYEQQoiIkgIhdjJp0iTk5OQ4OgxCGkTNXJB26eWXX0ZhYSF4/vZ50fDhwzFjxgwHRmXZzz//jPz8fDzzzDNYtGgRYmNj0blzZ0eHRdooSgqk3Zo7dy569+7t6DAadfXqVURGRkIQBPz1118ICgpydEikDaOkQEgthw4dwv79+3HXXXfhyJEj8Pb2xowZM9CrVy8AxqdUN27ciIsXL8LNzQ2PP/642NqlIAjYtWsXDh48iKKiInTs2BFz5swRW5I9e/Ysli9fjuLiYgwZMgQzZsxotFmVq1evYsKECcjKyoKfn5/YzDUhtkBJgRALLl++jOjoaCQkJOC3337Du+++i/Xr18PNzQ3vv/8+goODER8fj6ysLCxZsgQBAQGIiIjADz/8gOPHj2PevHno2LEjMjIyzNoTSk5OxooVK1BRUYG5c+ciKirKYvtGOp0Os2bNAmMMWq0Wc+bMgV6vhyAImD59OsaOHeuUTSSQOx8lBdJuvfPOO2Zn3VOmTBHP+D09PTF69GhwHIdBgwbh+++/R3JyMsLDw3Hx4kW8+eabkMvluOuuuzBy5EgcPnwYERER2L9/P6ZMmYLAwEAAwF133WW2znHjxsHV1RWurq7o2bMnrl+/bjEpyGQybN68Gfv370dmZiamT5+OpUuX4qmnnrLY5wYhrYWSAmm35syZU2+dglqtNivW8fPzg0ajQUFBAdzc3KBSqcRpvr6+YlPO+fn5DTaoWLN5b4VCAa1Wa3G+tWvXIjU1FZWVlZDJZDh48CC0Wi3S09PRsWNHrFixoknbSoi1KCkQYoFGowFjTEwMeXl5iIqKgre3N0pLS1FRUSEmhry8PLGdfB8fH9y8ebPFTSK/8sorEAQBzz//PD7++GOcOXMGJ0+exOzZs1u2YYQ0gp5TIMSCoqIi7N69G3q9HidPnsRff/2Fe++9F76+vujevTu++OILVFVVISMjAwcPHhR7Kxs5ciQSExORnZ0NxhgyMjJQUlLSrBj++usv+Pv7g+d5XLt2za5NkpP2i64USLv19ttvmz2n0Lt3b8yZMweAsU+B7OxszJgxA15eXvjnP/8pds7zj3/8Axs3bsQLL7wANzc3TJw4USyGGjNmDHQ6HZYuXYqSkhJ06tQJr7/+erPiu3r1Krp06SK+f/zxx1uyuYRYhfpTIKSW6ltSlyxZ4uhQCLE7Kj4ihBAioqRACCFERMVHhBBCRHSlQAghRERJgRBCiIiSAiGEEBElBUIIBd0ECQAAAA5JREFUISJKCoQQQkT/H+ztCkr7SUrcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAi486aIC94"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGBHVTM6NIKF"
      },
      "source": [
        "#To able the browser to open the camera in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhHsjTIdNHoe"
      },
      "source": [
        "def VideoCapture():\n",
        "  js = Javascript('''\n",
        "    async function create(){\n",
        "      div = document.createElement('div');\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.setAttribute('playsinline', '');\n",
        "\n",
        "      div.appendChild(video);\n",
        "\n",
        "      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: \"environment\"}});\n",
        "      video.srcObject = stream;\n",
        "\n",
        "      await video.play();\n",
        "\n",
        "      canvas =  document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "\n",
        "      div_out = document.createElement('div');\n",
        "      document.body.appendChild(div_out);\n",
        "      img = document.createElement('img');\n",
        "      div_out.appendChild(img);\n",
        "    }\n",
        "\n",
        "\n",
        "    async function capture(){\n",
        "        return await new Promise(function(resolve, reject){\n",
        "            pendingResolve = resolve;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            result = canvas.toDataURL('image/jpeg', 0.8);\n",
        "            pendingResolve(result);\n",
        "        })\n",
        "    }\n",
        "\n",
        "    function showimg(imgb64){\n",
        "        img.src = \"data:image/jpg;base64,\" + imgb64;\n",
        "    }\n",
        "\n",
        "  ''')\n",
        "  display(js)\n",
        "\n",
        "def byte2image(byte):\n",
        "  jpeg = b64decode(byte.split(',')[1])\n",
        "  im = Image.open(io.BytesIO(jpeg))\n",
        "  return np.array(im)\n",
        "\n",
        "def image2byte(image):\n",
        "  image = Image.fromarray(image)\n",
        "  buffer = io.BytesIO()\n",
        "  image.save(buffer, 'jpeg')\n",
        "  buffer.seek(0)\n",
        "  x = b64encode(buffer.read()).decode('utf-8')\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r0tDCr3LeVV"
      },
      "source": [
        "#Main Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-LljQb3Bw3"
      },
      "source": [
        "class face_recog:\n",
        "  def __init__(self):\n",
        "    return None\n",
        "  \n",
        "  def loading(self):\n",
        "    for i in range(3):\n",
        "      os.system(\"cls\")\n",
        "      print(\"[*] Loading.\")\n",
        "      sleep(1)\n",
        "      os.system(\"cls\")\n",
        "      print(\"[*] Loading..\")\n",
        "      sleep(1)\n",
        "      os.system(\"cls\")\n",
        "      print(\"[*] Loading...\")\n",
        "      sleep(1)\n",
        "  \n",
        "    for cl in self.myList:\n",
        "      curImg = cv2.imread(\"{}/{}\".format(self.path,cl))\n",
        "      self.images.append(curImg)\n",
        "      self.classNames.append(os.path.splitext(cl)[0])\n",
        "\n",
        "    print(\"[*] Pepole\")\n",
        "    sleep(1)\n",
        "    print(self.classNames)\n",
        "    sleep(1)\n",
        "    print(\"[*] Encoding...\")\n",
        "    self.encodeListKnown = self.__findEncodings(self.images)\n",
        "    print(\"[*] Encoding complete\")\n",
        "    sleep(1)\n",
        "    print(\"[*] Opening Camera... \")\n",
        "\n",
        "  def __findEncodings(self, images):\n",
        "      encodeList = []\n",
        "      for img in images:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        try:\n",
        "          encode = face_recognition.face_encodings(img)[0]\n",
        "        except IndexError as e:\n",
        "          print(e)\n",
        "        encodeList.append(encode)\n",
        "      return encodeList\n",
        "\n",
        "\"\"\"\n",
        "Crete \"Records.csv\" file to report everyone and their status\n",
        "\"\"\"\n",
        "  def Records(self, name, label):\n",
        "      with open('Records.csv','r+') as f:\n",
        "        import timeit\n",
        "        start = timeit.default_timer()\n",
        "        myDataList = f.readlines()\n",
        "        nameList = []\n",
        "        label == label\n",
        "        for line in myDataList:\n",
        "          entry = line.split(',')\n",
        "          nameList.append(entry[0])\n",
        "        if name not in nameList:\n",
        "          now = datetime.now()\n",
        "          dtString = now.strftime('%H:%M:%S')\n",
        "          f.writelines('\\n{},{},{}'.format(name,label,dtString))\n",
        "          stop = timeit.default_timer()\n",
        "          print('Time: ', stop - start) \n",
        "\n",
        "\n",
        "class face_mask(face_recog):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    ------> Create a dataset of your own pictures and names <------\n",
        "    Ex, Take one picture with mask and named it as \"Mohd_1.jpg\"\n",
        "    and then take onother picture without mask and named it as \"Mohd_2.jpg\"\n",
        "    after you are done, put all the images in a file \"Your_Own_Images\"\n",
        "    \"\"\"\n",
        "    self.path='/Your_Own_Images File Directory' \n",
        "    self.images = []\n",
        "    self.classNames = []\n",
        "    self.myList = os.listdir(self.path)\n",
        "    self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    face_recog.loading(self)\n",
        "    self.prototxtPath = r\"/face_detector/deploy.prototxt\"\n",
        "    self.weightsPath = r\"/face_detector/res10_300x300_ssd_iter_140000.caffemodel\"\n",
        "    return None\n",
        "\n",
        "  def __detect_mask(self, frame, faceNet, maskNet):\n",
        "    (h, w) = frame.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),\n",
        "      (104.0, 177.0, 123.0))\n",
        "    faceNet.setInput(blob)\n",
        "    detections = faceNet.forward()\n",
        "    faces = []\n",
        "    locs = []\n",
        "    preds = []\n",
        "\n",
        "    for i in range(0, detections.shape[2]):\n",
        "      confidence = detections[0, 0, i, 2]\n",
        "      if confidence > 0.5:\n",
        "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "        (startX, startY) = (max(0, startX), max(0, startY))\n",
        "        (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "        face = frame[startY:endY, startX:endX]\n",
        "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "        face = cv2.resize(face, (224, 224))\n",
        "        face = img_to_array(face)\n",
        "        face = preprocess_input(face)\n",
        "        faces.append(face)\n",
        "        locs.append((startX, startY, endX, endY))\n",
        "\n",
        "    if len(faces) > 0:\n",
        "      faces = np.array(faces, dtype=\"float32\")\n",
        "      preds = maskNet.predict(faces, batch_size=32)\n",
        "    return (locs, preds)\n",
        "\n",
        "  def main_proj(self):\n",
        "    faceNet = cv2.dnn.readNet(self.prototxtPath, self.weightsPath)\n",
        "    maskNet = load_model(\"/mask_detector.model\")\n",
        "    print(\"[INFO] starting video stream...\")\n",
        "    VideoCapture()\n",
        "    eval_js('create()')\n",
        "\n",
        "    while True:\n",
        "      byte = eval_js('capture()')\n",
        "      frame = byte2image(byte)\n",
        "      imgS = cv2.resize(frame, (0,0), None, 0.25,0.25)\n",
        "      imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        "      facesCurFrame = face_recognition.face_locations(imgS)\n",
        "      encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
        "      (locs, preds) = self.__detect_mask(frame, faceNet, maskNet)\n",
        "\n",
        "      for (box, pred) in zip(locs, preds):\n",
        "        (startX, startY, endX, endY) = box\n",
        "        (mask, withoutMask) = pred\n",
        "        label = \"Mask\" \n",
        "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "        if mask > withoutMask:\n",
        "          label = \"Mask\"\n",
        "        else:\n",
        "          lable = \"No Mask\"\n",
        "        \n",
        "        if label == \"Mask\": \n",
        "          label = \"With Mask\"\n",
        "          #print(\"yes with mask\")\n",
        "          # font = cv2.FONT_HERSHEY_DUPLEX\n",
        "          # cv2.putText(frame, \"WITH MASK\", (startX, startY - 10),\n",
        "          # font, 0.45, (255, 255, 255), 1)\n",
        "          # cv2.rectangle(frame, (startX, startY), (endX, endY), (255, 255, 255), 1)\n",
        "\n",
        "          for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
        "            matches = face_recognition.compare_faces(self.encodeListKnown, encodeFace)\n",
        "            faceDis = face_recognition.face_distance(self.encodeListKnown, encodeFace)\n",
        "            #print(faceDis)\n",
        "            matchIndex = np.argmin(faceDis)\n",
        "            if matches[matchIndex]:\n",
        "              name = self.classNames[matchIndex].upper()\n",
        "              #print(name)\n",
        "              #name = name + '\\n'  + lable\n",
        "              y1, x2, y2, x1 = faceLoc\n",
        "              y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "              self.Records(name, label)\n",
        "              #self.markAttendance(label)\n",
        "              cv2.rectangle(frame, (startX, startY), (endX, endY), (255, 255, 255), 1)\n",
        "              font = cv2.FONT_HERSHEY_DUPLEX\n",
        "              # cv2.putText(frame, name + \" -->  WITHOUT MASK\", (startX, startY - 10),\n",
        "              # font, 0.45, (0,0,0), 1)\n",
        "              text = name + '\\nWITH MASK'\n",
        "              y0, dy = 50, 25\n",
        " \n",
        "              for i, txt in enumerate(text.split('\\n')):\n",
        "                  y = y0+i*dy\n",
        "                  cv2.putText(frame, txt, (startX, y + 25), font,  0.60 , (255, 255, 255), 1)\n",
        "        else:\n",
        "          label = \"Without Mask\"\n",
        "          for encodeFace, faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
        "            matches = face_recognition.compare_faces(self.encodeListKnown, encodeFace)\n",
        "            faceDis = face_recognition.face_distance(self.encodeListKnown, encodeFace)\n",
        "            #print(faceDis)\n",
        "            matchIndex = np.argmin(faceDis)\n",
        "            if matches[matchIndex]:\n",
        "              name = self.classNames[matchIndex].upper()\n",
        "              #print(name)\n",
        "              #name = name + '\\n'  + lable\n",
        "              y1, x2, y2, x1 = faceLoc\n",
        "              y1, x2, y2, x1 = y1*4, x2*4, y2*4, x1*4\n",
        "              self.Records(name,label)\n",
        "              #self.markAttendance(label)\n",
        "              cv2.rectangle(frame, (startX, startY), (endX, endY), (0,0,0), 1)\n",
        "              font = cv2.FONT_HERSHEY_DUPLEX\n",
        "              # cv2.putText(frame, name + \" -->  WITHOUT MASK\", (startX, startY - 10),\n",
        "              # font, 0.45, (0,0,0), 1)\n",
        "              text = name + '\\nWITHOUT MASK'\n",
        "              y0, dy = 50, 25\n",
        " \n",
        "              for i, txt in enumerate(text.split('\\n')):\n",
        "                  y = y0+i*dy\n",
        "                  cv2.putText(frame, txt, (startX, y + 25), font,  0.60 , (0, 0, 0), 1)\n",
        "\n",
        "              #cv2.putText(frame, name + \"     WITHOUT MASK\", (startX, startY - 10),\n",
        "              #cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255),2)\n",
        "              #cv2.rectangle(frame,(x1,y2-35),(x2,y2),(0,0,255),cv2.FILLED)\n",
        "              #cv2.putText(frame,name,(x1+6,y2-6),self.font,1,(255,255,255),2)\n",
        "\n",
        "              #print(\"Person on Black List\")\n",
        "\n",
        "            # else:\n",
        "            #   cv2.putText(frame, \"without mask\", (startX, startY - 10),\n",
        "            #   self.font, 0.45, (0,0,255), 2)\n",
        "            #   cv2.rectangle(frame, (startX, startY), (endX, endY), (0,0,255), 2)\n",
        "            #   #print(\"without mask\")\n",
        "\n",
        "      print(label)\n",
        "      eval_js('showimg(\"{}\")'.format(image2byte(frame)))\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  obj = face_mask()\n",
        "  face_mask.main_proj.__call__(obj)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}